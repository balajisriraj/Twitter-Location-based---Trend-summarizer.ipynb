{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter Trend Finder - In Progress V0.1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpBNQqrJRddTVZXO67/5UZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balajisriraj/Twitter-Summary-mini-Project/blob/main/Twitter_Trend_Finder_In_Progress_V0_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddOsrd5-go4X"
      },
      "source": [
        "Project Flow:\n",
        "\n",
        "- Connect to Twittter API using the required creds\n",
        "- Find the Top trending Hashtags\n",
        "- Then filter the hashtags which are in English language\n",
        "- Filter Top 3 Hashtags from that\n",
        "- For these 3 hashtags, fetch 100 Tweets individually\n",
        "- Combain all the 100 tweets into one big corpus\n",
        "- Do basic Data Cleaning & Processing for better Tokenization\n",
        "- Using Text to Text transformer t5 model Summarize the tweets\n",
        "- Show Summarized text output for each Hashtag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls2e-QtLz9v_",
        "outputId": "3b214d9a-5314-48a1-ac10-4577ca55a962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "!pip install googletrans"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googletrans\n",
            "  Downloading https://files.pythonhosted.org/packages/71/3a/3b19effdd4c03958b90f40fe01c93de6d5280e03843cc5adf6956bfc9512/googletrans-3.0.0.tar.gz\n",
            "Collecting httpx==0.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2020.6.20)\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Collecting httpcore==0.9.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.0MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/82/4bd4b7d9c0d1dc0fbfbc2a1e00138e7f3ab85bc239358fe9b78aa2ab586d/sniffio-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Collecting hstspreload\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/c2/71d53bdee40a09e32ed3feba1aed15f912b5c20151fb6d43c6b37ac76a50/hstspreload-2020.9.29-py3-none-any.whl (961kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 8.2MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.5MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n",
            "\u001b[?25hCollecting contextvars>=2.1; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 5.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: googletrans, contextvars\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.0.0-cp36-none-any.whl size=15736 sha256=5fe14f99277152d4e4eb6cd1f5da8ac7683faa26814c3c23e52dac9becc7e7af\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/1a/a7/eaf4d7a3417a0c65796c547cff4deb6d79c7d14c2abd29273e\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=27dcba0fc969f83b7a566fc82d40b5f4d278afe90cbba6746f21d880c1ba3a85\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built googletrans contextvars\n",
            "Installing collected packages: rfc3986, immutables, contextvars, sniffio, h11, hyperframe, hpack, h2, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed contextvars-2.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.9.29 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 immutables-0.14 rfc3986-1.4.0 sniffio-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAVSA9sIY2si"
      },
      "source": [
        "Import Python Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhEISLWWAYZf"
      },
      "source": [
        "import pandas as pd\n",
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import API\n",
        "from googletrans import Translator\n",
        "import datetime\n",
        "import copy\n",
        "import string\n",
        "import re"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkhnje97AzM2"
      },
      "source": [
        "#Past the keys from your local drive\n",
        "consumer_key = '3YvJiFS5G13byIL9Kplm2gfOk'\n",
        "consumer_secret = 'eqmwYNrC7EGOyACIGmEwCErdWotSkzYBUnzJRUPtMVDKZOn1z6'\n",
        "access_token = '278398045-CLb3QRJeFpREuSnLbbvERWBigJMTf4dsfLXD6LtI'\n",
        "access_token_secret = 'krACZJgoBisTsK6T1ikYSCZNVnvTlScb0vSV3kVnE42Wi'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JLrr96DA0lD"
      },
      "source": [
        "# Consumer key authentication(consumer_key,consumer_secret can be collected from our twitter developer profile)\n",
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "# Access key authentication(access_token,access_token_secret can be collected from our twitter developer profile)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "# Set up the API with the authentication handler\n",
        "api = API(auth)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQMoZmjjDMhO"
      },
      "source": [
        "WOE_ID = 2295424 # Where on Earth id can be extracted from https://nations24.com/world-wide\n",
        "lan_find = Translator() # for finding teh language of the hashtags"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs8rjQFVCvpF"
      },
      "source": [
        "def get_location_trends(locations, auth,n_hashtags,lang):\n",
        "  api = API(auth)\n",
        "  trends = api.trends_place(locations)\n",
        "  data = trends[0]\n",
        "  trends_data = data['trends']\n",
        "  global tred_data\n",
        "  tred_data = []\n",
        "  for info in trends_data:\n",
        "    tred_data.append([info['name'],info['tweet_volume'],lan_find.detect(info['name']).lang ] )\n",
        "  tred_data = pd.DataFrame(tred_data, columns = list(['Hashtag',\n",
        "                                                    'Tweet_Volume', 'Language'])).sort_values(by = ['Tweet_Volume'],ascending = False)\n",
        "  #select english language trends\n",
        "  tred_data = tred_data[tred_data.Language == lang]\n",
        "  #select top 3 trends\n",
        "  tred_data = tred_data.nlargest(n_hashtags,columns=['Tweet_Volume'])\n",
        "  return tred_data"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7jC8BaWETNk",
        "outputId": "04c425b8-efe5-42ae-c2da-604b45708565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "df_trending = get_location_trends(WOE_ID,auth,3,'en')\n",
        "df_trending"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hashtag</th>\n",
              "      <th>Tweet_Volume</th>\n",
              "      <th>Language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>#PCAs</td>\n",
              "      <td>2098175.0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>President Trump</td>\n",
              "      <td>1499208.0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>#BTSonFallon_D5</td>\n",
              "      <td>330983.0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Hashtag  Tweet_Volume Language\n",
              "37            #PCAs     2098175.0       en\n",
              "10  President Trump     1499208.0       en\n",
              "20  #BTSonFallon_D5      330983.0       en"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w23ffhlY0e2C"
      },
      "source": [
        "hashtag_list = list(df_trending['Hashtag'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGGsDHjcjp5A"
      },
      "source": [
        "def extract_tweets_for_htags(no_of_tweets):\n",
        "  dict_of_df = {} \n",
        "  for htag in hashtag_list:\n",
        "    today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    tweets = tweepy.Cursor(api.search,q=htag,lang=\"en\",since=today).items(no_of_tweets) #Extracting tweets for the htag\n",
        "    tweets= [tweet.text for tweet in tweets] # Saving the tweets as list\n",
        "    \n",
        "    \n",
        "    key_name = 'df_htag_'+str(htag)\n",
        "    dict_of_df[key_name] = copy.deepcopy(tweets)\n",
        "  return dict_of_df"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bdlXDbO2gLf"
      },
      "source": [
        "dict_of_df = extract_tweets_for_htags(3)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LtN2SBGytWL"
      },
      "source": [
        "hashtag_df_list = dict_of_df.keys() #List contains individual the key names for accessing the data inside the dictionary"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vueaq_m-8MHg"
      },
      "source": [
        "temp_list = dict_of_df['df_htag_#PCAs']"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL4td9dh9xxT"
      },
      "source": [
        "def remove_pattern(text, pattern):\n",
        "    clean_text = []\n",
        "    for tweet in text:\n",
        "      r = re.findall(pattern, tweet)\n",
        "      for i in tweet:\n",
        "          input_txt = re.sub(i, '', tweet)\n",
        "          clean_text.append(text)\n",
        "          break\n",
        "    return clean_text"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7MQWdH7_Csx",
        "outputId": "656317c0-d9a0-4d49-bb69-95db02aaf751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "remove_pattern(text = temp_list, pattern = \"@[\\w]*\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwZLdEl00MFK"
      },
      "source": [
        "def remove_punct(text):\n",
        "    clean_text = []\n",
        "    for tweet in text:\n",
        "      text  = \"\".join([char for char in tweet if char not in string.punctuation])\n",
        "      text = re.sub('[0-9]+', '', text)\n",
        "      clean_text.append(text)\n",
        "    return clean_text"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzHljY2F7zIO",
        "outputId": "f56489d7-34e9-4285-e8b6-447713d88e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "remove_punct(temp_list)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT WorldwideBLINK I vote IceCream by BLACKPINK and selenagomez for TheMusicVideo on this years Peoples Choice Awards PCAs',\n",
              " 'bpbillboard thebluesies BLACKPINK I vote BLACKPINK\\xa0￼\\xa0 for TheGroup on this years Peoples Choice Awards PCAs BLACKPINK',\n",
              " 'RT fetishforsell Since yall are here lets help selena win the award since she had been supporting the pinks since the beginning \\n\\nRETWE…']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaMnv_ks9XOu",
        "outputId": "41dbaa46-010c-4845-ce4c-6e15f9a7c471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "temp_list"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"RT @WorldwideBLINK: I vote #IceCream by @BLACKPINK and @selenagomez for #TheMusicVideo on this year's People's Choice Awards #PCAs\",\n",
              " \"@bpbillboard @thebluesies @BLACKPINK I vote #BLACKPINK\\xa0￼\\xa0 for #TheGroup on this year's People's Choice Awards #PCAs @BLACKPINK\",\n",
              " \"RT @fetishforsell: Since y'all are here let's help selena win the award since she had been supporting the pinks since the beginning \\n\\nRETWE…\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrwg0NEq9q1e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}